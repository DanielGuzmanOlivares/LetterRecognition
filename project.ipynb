{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import itertools\n",
    "from PIL import Image,ImageEnhance,ImageFilter\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import multiprocessing\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score,KFold,cross_val_predict,train_test_split,GridSearchCV\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression,SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import normalize\n",
    "from itertools import groupby\n",
    "from random import randint\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variables\n",
    "%matplotlib inline\n",
    "dataDir = \"./data/out/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construcción de DataFrame y Tratamiento de Imagenes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos aprovechamos de que las imágenes tienen la letra en el nombre del archivo, para cada imagen realzamos el contraste y la ponemos en blanco y negro (en la memoria estaría guay poner algo tipo, antes del tratamiento y después). Las imágenes originalmente tienen unas dimensiones de 160x120, nosotros para el DataFrame las expandimos, y tenemos un DataFrame final de 19801 columnas (19800 de cada pixel y 1 del etiquetado de la letra a la que corresponde esa imagen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(dataDir)\n",
    "l1 = []\n",
    "cols = []\n",
    "height = None\n",
    "width = None\n",
    "for file in files:\n",
    "    with open(dataDir+file,\"rb\") as f:\n",
    "        im = Image.open(dataDir+file)\n",
    "        enhancer = ImageEnhance.Contrast(im)\n",
    "        im = enhancer.enhance(4.)\n",
    "        #im = im.filter(ImageFilter.GaussianBlur(radius=4))\n",
    "        label = file.split(\"_\")[1].split(\".\")[0]\n",
    "        imArray = np.array(im)\n",
    "        imArray[imArray >= 128] = 255\n",
    "        imArray[imArray < 128] = 0\n",
    "        height,width = imArray.shape\n",
    "        l1.append([bit for bit in imArray.reshape(imArray.shape[0]*imArray.shape[1])]+[label]) #Todos los bits de la imagen\n",
    "        \n",
    "df = pd.DataFrame(l1)\n",
    "for i in range(height):\n",
    "    for j in range(width):\n",
    "        cols.append(\"%dx%d\"%(i,j))\n",
    "cols.append(\"Label\")\n",
    "df.columns = cols        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta función permite ver las imagenes del DataFrame con el que trabajamos, solo hay que pasarle el DataFrame, la fila y la forma de la imagen original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showImage(df,row,shape):\n",
    "    data = np.asarray(df.iloc[row,:-1],dtype=np.uint8).reshape(shape)\n",
    "    img = Image.fromarray(data)\n",
    "    img.show()\n",
    "showImage(df,346,(height,width))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como nos piden probar con distintos clasificadores y distintas configuraciones,  la función `fitHyperparameter` encuentra los parámetros óptimos en un rango mediante GridSearch y validación cruzada para unos datos dado un clasificador y unos datos.\n",
    "La función `testClassifiers` prueba distintos clasificadores que vienen dados por un diccionario\n",
    "\n",
    "`clfs = {\n",
    "        \"NombreClasificador\":{\"clf\": ClaseClasificador(),\"confs\":{\"parametro\":posibles valores,\"parametro\":.....}\n",
    "        ...\n",
    "       }  `   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MLP': {'conf': {'activation': 'relu', 'alpha': 0.0001, 'batch_size': 'auto', 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': False, 'epsilon': 1e-08, 'hidden_layer_sizes': (20, 20), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'max_iter': 200, 'momentum': 0.9, 'n_iter_no_change': 10, 'nesterovs_momentum': True, 'power_t': 0.5, 'random_state': 1, 'shuffle': True, 'solver': 'adam', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': False, 'warm_start': False}, 'acc': 0.09090909090909091}, 'RandomForest': {'conf': {'bootstrap': True, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 140, 'n_jobs': 8, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False}, 'acc': 0.8}, 'KNN': {'conf': {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': 8, 'n_neighbors': 4, 'p': 2, 'weights': 'distance'}, 'acc': 0.7454545454545455}, 'SVM': {'conf': {'C': 0.25, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 'auto_deprecated', 'kernel': 'linear', 'max_iter': -1, 'probability': False, 'random_state': None, 'shrinking': True, 'tol': 0.001, 'verbose': False}, 'acc': 0.7545454545454545}, 'Logistic Regression': {'conf': {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 40, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'none', 'random_state': None, 'solver': 'saga', 'tol': inf, 'verbose': 0, 'warm_start': False}, 'acc': 0.5454545454545454}, 'SGD': {'conf': {'alpha': 0.0001, 'average': False, 'class_weight': None, 'early_stopping': False, 'epsilon': 0.1, 'eta0': 0.1, 'fit_intercept': True, 'l1_ratio': 0.15, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 40, 'n_iter_no_change': 5, 'n_jobs': None, 'penalty': 'l2', 'power_t': 0.5, 'random_state': None, 'shuffle': True, 'tol': inf, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}, 'acc': 0.4818181818181818}}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def fitHyperparameter(clf,conf,X,y,splits,njobs=multiprocessing.cpu_count()):\n",
    "    opt = GridSearchCV(clf,conf,cv=splits,n_jobs=njobs,iid=False)\n",
    "    search = opt.fit(X, y)\n",
    "    clf.set_params(**search.best_params_)\n",
    "    return clf\n",
    "\n",
    "\n",
    "def testClassifiers(clfs,data,testSize,splits):\n",
    "    results = {}\n",
    "    X,y = data.iloc[:,:-1],data.iloc[:,-1]\n",
    "    xTrain, xTest, yTrain, yTest = train_test_split(X, y, test_size=testSize)\n",
    "    for c in clfs:\n",
    "        clf,conf = clfs[c][\"clf\"],clfs[c][\"confs\"]\n",
    "        clf = fitHyperparameter(clf,conf,xTrain,yTrain,splits)\n",
    "        clf.fit(xTrain,yTrain)\n",
    "        results[c] = {\"conf\":clf.get_params(),\"acc\":accuracy_score(yTest, clf.predict(xTest), normalize=True, sample_weight=None)}\n",
    "    return results\n",
    "\n",
    "\n",
    "clfs = {\n",
    "        \"MLP\":{\"clf\": MLPClassifier(max_iter=200,hidden_layer_sizes=(20,20), random_state=1),\"confs\":{\"solver\":(\"lbfgs\",\"adam\",\"sgd\")}},\n",
    "        \"RandomForest\":{\"clf\":RandomForestClassifier(n_jobs=8,),\"confs\":{\"n_estimators\":range(10,200,10)}},\n",
    "        \"KNN\":{\"clf\":KNeighborsClassifier(n_jobs=8),\"confs\":{\"n_neighbors\":range(1,10),\"weights\":(\"uniform\",\"distance\")}},\n",
    "        \"SVM\":{\"clf\":svm.SVC(C=0.25),\"confs\":{\"kernel\":(\"rbf\",\"linear\",\"sigmoid\")}},\n",
    "        \"Logistic Regression\":{\"clf\": LogisticRegression(tol=np.inf,multi_class=\"multinomial\"),\"confs\":{\"penalty\":(\"none\",\"l2\"),\"solver\":(\"lbfgs\",\"sag\",\"saga\"),\"max_iter\":range(10,100,15)}},\n",
    "        \"SGD\":{\"clf\":SGDClassifier(eta0=0.5,learning_rate='constant',tol=np.inf),\"confs\":{\"eta0\":np.linspace(0.1,2,10),\"max_iter\":range(10,50,10)}}\n",
    "       }      \n",
    "print(testClassifiers(clfs,df,0.1,5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nuevo Clasificador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto en la memoria lo explico yo, no worries, basicamente detecta patrones y hace similitudes con ellos, tiene un 0.98 de acierto por validación cruzada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getImagePatterns(img,storage,patternSensibility=3):\n",
    "        patternQueue = []\n",
    "        for row in img:\n",
    "            pattern = getPattern(row)\n",
    "            if len(patternQueue) == 0:\n",
    "                patternQueue.append(pattern)\n",
    "            elif patternQueue[-1] == pattern:\n",
    "                patternQueue.append(pattern)\n",
    "                if len(patternQueue) == patternSensibility:\n",
    "                    patternQueue = []\n",
    "                    if len(storage) == 0:\n",
    "                        storage.append((pattern,1))\n",
    "                    elif pattern != storage[-1][0]:\n",
    "                        storage.append((pattern,1))\n",
    "                    else:\n",
    "                        storage[-1] = (storage[-1][0],storage[-1][1] + 1)\n",
    "            else:\n",
    "                patternQueue = [pattern]\n",
    "\n",
    "def getSimilarityScore(imagePatterns1,imagePatterns2):\n",
    "        count = 0\n",
    "\n",
    "        if len(imagePatterns1) < len(imagePatterns2):\n",
    "            minList = imagePatterns1\n",
    "            maxList = imagePatterns2\n",
    "        else:\n",
    "            minList = imagePatterns2\n",
    "            maxList = imagePatterns1\n",
    "\n",
    "        for i,x in enumerate(minList):\n",
    "            if x[0] == maxList[i][0]:\n",
    "                count += 1/(1+abs(x[1] - maxList[i][1]))\n",
    "            else:\n",
    "                continue \n",
    "\n",
    "        return count/len(maxList)\n",
    "\n",
    "def getPattern(row,patternTrigger=5):\n",
    "        pattern = []\n",
    "        aux = []\n",
    "        counter = 0\n",
    "        color = -1\n",
    "        i = 0\n",
    "        while i < len(row):\n",
    "            if color == row[i]:\n",
    "                counter += 1\n",
    "                if counter >= patternTrigger:\n",
    "                    pattern.append(color)\n",
    "                    counter = 0\n",
    "            else:\n",
    "                counter = 1\n",
    "                color = row[i]\n",
    "            i += 1\n",
    "\n",
    "        return [cl for cl,_ in flatList(pattern)]\n",
    "        \n",
    "\n",
    "def flatList(l):\n",
    "        flat=[]\n",
    "        actual = l[0]\n",
    "        count = 0\n",
    "        i = 0\n",
    "        while i < len(l):\n",
    "            if i+1 == len(l):\n",
    "                flat.append((l[i],count+1))\n",
    "            elif l[i+1] == l[i]:\n",
    "                count +=1\n",
    "            else:\n",
    "                flat.append((l[i],count+1))\n",
    "                count = 0\n",
    "\n",
    "            i += 1\n",
    "        return flat\n",
    "\n",
    "def cont(data):\n",
    "    originalShape = data.shape\n",
    "    HCont,VCont = [],[]\n",
    "    for row in data:\n",
    "        row = list(row)\n",
    "        \n",
    "        if 0 in row:\n",
    "            first = row.index(0)\n",
    "            row.reverse()\n",
    "            last = (- row.index(0) -1) % len(row)\n",
    "            row.reverse()\n",
    "            HCont.append([0 if i >= first and i <=  last else 255 for i in range(len(row))])\n",
    "        else:\n",
    "            HCont.append(row)\n",
    "    for row in np.transpose(data):\n",
    "        row = list(row)\n",
    "            first = row.index(0)\n",
    "            row.reverse()\n",
    "            last = (- row.index(0) -1) % len(row)\n",
    "            row.reverse()\n",
    "            VCont.append([0 if i >= first and i <=  last else 255 for i in range(len(row))])\n",
    "        else:\n",
    "            VCont.append(row)\n",
    "    \n",
    "    HCont = np.array(HCont,dtype=np.uint8).reshape(originalShape)\n",
    "    VCont = np.transpose(np.array(VCont,dtype=np.uint8))\n",
    "    \n",
    "    ret = HCont + VCont\n",
    "    ret[ret > 250] = 255\n",
    "    ret[ret < 250] = 0\n",
    "    return ret\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class block():\n",
    "    Hpatterns = []\n",
    "    Vpatterns = []\n",
    "    width = None\n",
    "    blackOverWhite = 0.\n",
    "    \n",
    "    def __init__(self,width):\n",
    "        self.Hpatterns = []\n",
    "        self.Vpatterns = []\n",
    "        self.blackOverWhite = 0.\n",
    "        self.width = width\n",
    "    \n",
    "    \n",
    "    def match(self,image):\n",
    "        HScore,Vscore = 0,0\n",
    "        Hpatterns = []\n",
    "        getImagePatterns(image,Hpatterns)\n",
    "        Hscore = getSimilarityScore(self.Hpatterns,Hpatterns)\n",
    "        \n",
    "        Vpatterns = []\n",
    "        getImagePatterns(np.transpose(image),Vpatterns)\n",
    "        Vscore = getSimilarityScore(self.Vpatterns,Vpatterns)\n",
    "        \n",
    "        return Hscore*Vscore\n",
    "        \n",
    "        \n",
    "    \n",
    "    def generatePatterns(self,image):\n",
    "        vals,counts = np.unique(image,return_counts=True)\n",
    "        self.blackOverWhite = counts[np.where(vals == 0)]/sum(counts)\n",
    "        self.width = image.shape[1]\n",
    "        getImagePatterns(image,self.Hpatterns)\n",
    "        getImagePatterns(np.transpose(image),self.Vpatterns)\n",
    "    \n",
    "\n",
    "                        \n",
    "    def __eq__(self,other):\n",
    "        if other.Hpatterns == self.Hpatterns and other.Vpatterns == self.Vpatterns:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "\n",
    "            \n",
    "class PatternClassifier():\n",
    "    patterns = {}\n",
    "    classes = None\n",
    "    \n",
    "    def __init__(self,classes,height,width):\n",
    "        self.classes = classes\n",
    "        self.patterns = {cl:{\"ink\":.0,\"blocks\":[]} for cl in classes}    \n",
    "    \n",
    "    def fit(self,X,y):\n",
    "        for cl in self.classes:\n",
    "            bOW  = []\n",
    "            imgs = np.array(X.iloc[np.where(y == cl)])\n",
    "            for img in imgs:\n",
    "                img = img.reshape((height,width))\n",
    "                img = cont(img) \n",
    "                vals,counts = np.unique(img,return_counts=True)\n",
    "                bOW.append(counts[np.where(vals == 0)]/sum(counts))\n",
    "                b = block(width)\n",
    "                b.generatePatterns(img)\n",
    "                if b not in self.patterns[cl][\"blocks\"]:\n",
    "                    self.patterns[cl][\"blocks\"].append(b)\n",
    "            self.patterns[cl][\"ink\"] = np.mean(np.array(bOW))\n",
    "    \n",
    "    def predict(self,X):\n",
    "        y = []\n",
    "        for i,x in enumerate(np.array(X)):\n",
    "            matches = []\n",
    "            maxMatches = []\n",
    "            #print(i,\"/\",height)\n",
    "            img = x.reshape((height,width))\n",
    "            img = cont(img)\n",
    "\n",
    "            for cl in self.classes:\n",
    "                for b in self.patterns[cl][\"blocks\"]:\n",
    "                    matches.append((b.match(img),cl))\n",
    "            \n",
    "            sortedMatches = sorted(matches,reverse=True)\n",
    "            \n",
    "            parts = []\n",
    "            for cl in self.classes:\n",
    "                parts.append((np.mean([fit for fit,c in sortedMatches if c == cl][:3]),cl))\n",
    "            y.append(sorted(parts,reverse=True)[0][1])\n",
    "\n",
    "                \n",
    "        return y\n",
    "\n",
    "\n",
    "            \n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc Cross validated: 0.9800000000000001\n"
     ]
    }
   ],
   "source": [
    "acc = []\n",
    "X = df.iloc[:,:-1]\n",
    "y = df.iloc[:,-1]\n",
    "kf = KFold(n_splits=10, shuffle=True)\n",
    "pc = PatternClassifier(np.unique(y),height,width)\n",
    "for train_index, test_index in kf.split(X):\n",
    "    xTrain = X.iloc[train_index]\n",
    "    yTrain = y.iloc[train_index]\n",
    "    xTest = X.iloc[test_index]\n",
    "    yTest = y.iloc[test_index]\n",
    "    pc.fit(xTrain, yTrain)\n",
    "    sc = accuracy_score(yTest, pc.predict(xTest), normalize=True, sample_weight=None)\n",
    "    acc.append(sc)\n",
    "print(\"Acc Cross validated:\",np.mean(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
